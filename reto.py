# -*- coding: utf-8 -*-
"""RETO.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10X-EE3Pul_v1rksxvyi-4RVmAY3rfKrA
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

data = pd.read_csv('final.csv', encoding='utf-8')

data.info()

import pandas as pd



# Preprocesamiento de los datos
#data = data[['Satis_ODS', 'Satis_Aporte', 'Satis_Interaccion', 'Satis_Herramientas',
#             'Satis_Liderazgo_OSF', 'Satis_IT', 'Retro_OSF', 'Causa_Interesante',
#             'Opp_Egoismo', 'Nvl_Responsabilidad', 'Respeto_Diversidad',
 #            'Promover_Soluciones', 'Satis_Exp', 'roberta_neg_Exp', 'roberta_neu_Exp',
  #           'roberta_pos_Exp', 'roberta_neg_OSF', 'roberta_neu_OSF', 'roberta_pos_OSF',"OSF_encoded"]]
#data.dropna(inplace=True)

# Remover valores fuera del rango esperado
#data = data[(data['Satis_Exp'] >= 1) & (data['Satis_Exp'] <= 5)]

# Dividir los datos en conjuntos de entrenamiento y prueba
X = data[['Satis_ODS', 'Satis_Aporte', 'Satis_Interaccion', 'Satis_Herramientas',
             'Satis_Liderazgo_OSF', 'Satis_IT', 'Retro_OSF', 'Causa_Interesante',
             'Opp_Egoismo', 'Nvl_Responsabilidad', 'Respeto_Diversidad',
             'Promover_Soluciones', 'roberta_neg_Exp', 'roberta_neu_Exp',
             'roberta_pos_Exp', 'roberta_neg_OSF', 'roberta_neu_OSF', 'roberta_pos_OSF',"OSF_encoded"]]
y = data['Satis_Exp']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Escalar los datos de entrada
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Codificar las etiquetas en formato one-hot
num_classes = 5
y_train_onehot = to_categorical(y_train - 1, num_classes)
y_test_onehot = to_categorical(y_test - 1, num_classes)

# Definir la arquitectura del modelo
model = Sequential()
model.add(Dense(100, input_shape=(19,), activation='relu'))
model.add(Dense(100, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))

# Compilar el modelo
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Entrenar el modelo
model.fit(X_train, y_train_onehot, validation_data=(X_test, y_test_onehot), epochs=25, batch_size=35)

# Evaluar el modelo en los datos de prueba
loss, accuracy = model.evaluate(X_test, y_test_onehot)
print('Loss:', loss)
print('Accuracy:', accuracy)
